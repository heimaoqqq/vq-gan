# å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾åƒæ¡ä»¶ç”Ÿæˆ - å®Œæ•´æŒ‡å—

åŸºäºLatent Diffusionå’ŒClassifier-Free Guidanceçš„æ¡ä»¶DDPMç”Ÿæˆç³»ç»Ÿ

---

## ğŸ“‹ é¡¹ç›®æ¦‚è§ˆ

**ç›®æ ‡**ï¼šä½¿ç”¨æ¡ä»¶DDPMç”Ÿæˆå¾®å¤šæ™®å‹’æ—¶é¢‘å›¾åƒï¼Œé€šè¿‡åˆæˆæ•°æ®å¢å¼ºResNet18åˆ†ç±»å™¨æ€§èƒ½

**æŠ€æœ¯æ ˆ**ï¼š
- Latent Diffusion Model (åœ¨VAEæ½œåœ¨ç©ºé—´32Ã—32Ã—4è®­ç»ƒ)
- Classifier-Free Guidance (æ¡ä»¶ç”Ÿæˆ31ä¸ªç”¨æˆ·)
- Min-SNR Loss Weighting (å°æ•°æ®é›†ä¼˜åŒ–)

**æ•°æ®è¯´æ˜**ï¼š
- 31ä¸ªç”¨æˆ·ï¼Œæ¯ç”¨æˆ·å›¾åƒæ•°é‡ä¸å›ºå®šï¼ˆçº¦140-160å¼ ï¼‰
- DDPMè®­ç»ƒï¼šæ¯ç”¨æˆ·å›ºå®šå–50å¼ ï¼ˆéšæœºæ‰“ä¹±åï¼Œå…±1550å¼ ï¼‰
- åˆ†ç±»å™¨æµ‹è¯•ï¼šæ¯ç”¨æˆ·å‰©ä½™å›¾åƒï¼ˆ90-110å¼ ä¸ç­‰ï¼Œå…±çº¦3100å¼ ï¼‰
- å›ºå®šéšæœºç§å­42ï¼Œå®Œå…¨å¯å¤ç°

**ç¡¬ä»¶**ï¼šKaggle P100 16GB

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®Œæ•´å·¥ä½œæµï¼ˆ3æ­¥ï¼‰

```bash
# === Kaggle Notebook ===

# 1. å…‹éš†å’Œå®‰è£…
!git clone https://github.com/heimaoqqq/denoising_diffusion_pytorch.git
%cd denoising_diffusion_pytorch
!pip install -e .

# 2. é¢„ç¼–ç ï¼ˆ30åˆ†é’Ÿï¼ŒåŒ…å«è®­ç»ƒ+æµ‹è¯•é›†ï¼‰
!python preprocess_latents.py

# 3. è®­ç»ƒDDPMï¼ˆ4å°æ—¶ï¼‰
!python train_latent_cfg.py
```

---

## ğŸ“‚ è¾“å‡ºæ–‡ä»¶è¯´æ˜

### é¢„ç¼–ç è¾“å‡º

```
latents_cache/
â”œâ”€â”€ data_split.json           â† æ•°æ®é›†åˆ’åˆ†ä¿¡æ¯ï¼ˆé‡è¦ï¼ï¼‰
â”œâ”€â”€ user_00_*.pt              â† ç”¨æˆ·1çš„æ½œåœ¨è¡¨ç¤º
â”œâ”€â”€ user_01_*.pt              â† ç”¨æˆ·2çš„æ½œåœ¨è¡¨ç¤º
...
â””â”€â”€ user_30_*.pt              â† ç”¨æˆ·31çš„æ½œåœ¨è¡¨ç¤º

æ€»è®¡: çº¦4600-5000ä¸ª.ptæ–‡ä»¶ï¼ˆå–å†³äºæ¯ç”¨æˆ·å®é™…å›¾åƒæ•°ï¼‰
  - è®­ç»ƒé›†: 1550ä¸ªï¼ˆ31Ã—50ï¼Œå›ºå®šï¼‰
  - æµ‹è¯•é›†: çº¦3000-3400ä¸ªï¼ˆå‰©ä½™å›¾åƒï¼Œæ•°é‡ä¸å›ºå®šï¼‰
å¤§å°: ~150MB
```

### data_split.json ç”¨é€”

**åŒ…å«ä¿¡æ¯**ï¼š
- æ¯ä¸ªç”¨æˆ·çš„è®­ç»ƒé›†å›¾åƒè·¯å¾„ï¼ˆ50å¼ ï¼‰
- æ¯ä¸ªç”¨æˆ·çš„æµ‹è¯•é›†å›¾åƒè·¯å¾„ï¼ˆ100å¼ ï¼‰
- éšæœºç§å­ã€ç”¨æˆ·æ ‡ç­¾ç­‰å…ƒæ•°æ®

**ç”¨äº**ï¼š
1. âœ… ç¡®ä¿DDPMè®­ç»ƒå’Œåˆ†ç±»å™¨è®­ç»ƒä½¿ç”¨ç›¸åŒçš„è®­ç»ƒé›†
2. âœ… åŠ è½½æµ‹è¯•é›†è¿›è¡Œåˆ†ç±»å™¨è¯„ä¼°
3. âœ… å¯å¤ç°å®éªŒï¼ˆè®°å½•äº†ç¡®åˆ‡çš„åˆ’åˆ†ï¼‰
4. âœ… åˆ†ææ¯ä¸ªç”¨æˆ·çš„æ•°æ®åˆ†å¸ƒ

### DDPMè®­ç»ƒè¾“å‡º

```
results/
â”œâ”€â”€ model-*.pt               â† DDPMæ£€æŸ¥ç‚¹
â””â”€â”€ sample-*.png             â† ç”Ÿæˆæ ·æœ¬ï¼ˆç›‘æ§ç”¨ï¼‰
```

### åˆæˆæ•°æ®è¾“å‡º

```
synthetic_data/
â”œâ”€â”€ checkpoint_50/
â”‚   â”œâ”€â”€ user_00_sample_000.png
â”‚   â”œâ”€â”€ user_00_sample_001.png
â”‚   ...
â”‚   â””â”€â”€ user_30_sample_049.png  (31ç”¨æˆ·Ã—50å¼ )
â”œâ”€â”€ checkpoint_75/
...
```

---

## ğŸ”¬ åˆ†ç±»å™¨å®éªŒæµç¨‹

### æ–¹æ³•1ï¼šä½¿ç”¨ç¤ºä¾‹è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# åŸºå‡†å®éªŒï¼ˆä»…çœŸå®æ•°æ®ï¼‰
!python classifier_experiment_example.py \
    --data_root /kaggle/input/organized-gait-dataset/Normal_line \
    --split_file latents_cache/data_split.json \
    --epochs 100

# è¾“å‡º:
# åŠ è½½æ•°æ®é›†
# Loaded train set: 1550 images, 31 users
# Loaded test set: 3100 images, 31 users
# æ•´ä½“å‡†ç¡®ç‡: XX.XX% (baseline)

# å¢å¼ºå®éªŒï¼ˆçœŸå®+åˆæˆï¼‰
!python classifier_experiment_example.py \
    --data_root /kaggle/input/organized-gait-dataset/Normal_line \
    --split_file latents_cache/data_split.json \
    --synthetic_folder synthetic_data/checkpoint_75 \
    --epochs 100

# è¾“å‡º:
# å¢å¼ºåè®­ç»ƒé›†: 3100 å¼ ï¼ˆçœŸå®1550 + åˆæˆ1550ï¼‰
# æ•´ä½“å‡†ç¡®ç‡: YY.YY% (enhanced)
```

### æ–¹æ³•2ï¼šè‡ªå®šä¹‰è„šæœ¬

```python
from load_dataset import MicroDopplerDataset
from torch.utils.data import DataLoader

# 1. åŠ è½½è®­ç»ƒé›†ï¼ˆä½¿ç”¨data_split.jsonï¼‰
train_ds = MicroDopplerDataset(
    data_root='/kaggle/input/organized-gait-dataset/Normal_line',
    split_file='latents_cache/data_split.json',
    split='train',      # 'train' æˆ– 'test'
    use_latents=False   # False=åŸå§‹å›¾åƒï¼ŒTrue=æ½œåœ¨è¡¨ç¤º
)

# 2. åŠ è½½æµ‹è¯•é›†
test_ds = MicroDopplerDataset(
    data_root='/kaggle/input/organized-gait-dataset/Normal_line',
    split_file='latents_cache/data_split.json',
    split='test'
)

# 3. åˆ›å»ºDataLoader
train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)

# 4. è®­ç»ƒæ‚¨çš„ResNet18
from torchvision.models import resnet18
import torch.nn as nn

model = resnet18(pretrained=False, num_classes=31)
# ... è®­ç»ƒä»£ç  ...

# 5. è¯„ä¼°
accuracy = evaluate(model, test_loader)
```

---

## ğŸ“Š æ•°æ®é›†ä½¿ç”¨è¯´æ˜

### DDPMè®­ç»ƒï¼ˆtrain_latent_cfg.pyï¼‰

```python
ä½¿ç”¨æ•°æ®:
  âœ“ è®­ç»ƒé›†: 1550å¼ ï¼ˆdata_split.jsonä¸­çš„train_imagesï¼‰
  âœ— æµ‹è¯•é›†: ä¸ä½¿ç”¨ï¼ˆå¯¹DDPMå®Œå…¨ä¸å¯è§ï¼‰

æ•°æ®åŠ è½½:
  - LatentDatasetè‡ªåŠ¨ä½¿ç”¨ä¸preprocessç›¸åŒçš„åˆ’åˆ†é€»è¾‘
  - ç¡®ä¿é€‰æ‹©ç›¸åŒçš„1550å¼ è®­ç»ƒå›¾åƒ
  - ç›´æ¥è¯»å–latents_cache/ä¸­çš„.ptæ–‡ä»¶
```

### åˆ†ç±»å™¨å®éªŒï¼ˆclassifier_experiment_example.pyï¼‰

```python
åŸºå‡†åˆ†ç±»å™¨:
  è®­ç»ƒ: çœŸå®è®­ç»ƒé›†1550å¼ ï¼ˆdata_split.jsonçš„train_imagesï¼‰
  æµ‹è¯•: çœŸå®æµ‹è¯•é›†3100å¼ ï¼ˆdata_split.jsonçš„test_imagesï¼‰
  
å¢å¼ºåˆ†ç±»å™¨:
  è®­ç»ƒ: çœŸå®è®­ç»ƒé›†1550 + åˆæˆæ•°æ®Nå¼ 
  æµ‹è¯•: çœŸå®æµ‹è¯•é›†3100å¼ ï¼ˆç›¸åŒçš„æµ‹è¯•é›†ï¼‰
  
å…³é”®:
  âœ“ ä¸¤ä¸ªå®éªŒä½¿ç”¨å®Œå…¨ç›¸åŒçš„è®­ç»ƒ/æµ‹è¯•åˆ’åˆ†
  âœ“ æµ‹è¯•é›†å§‹ç»ˆç‹¬ç«‹ï¼Œä»æœªç”¨äºDDPMè®­ç»ƒ
  âœ“ å¯ä»¥å…¬å¹³å¯¹æ¯”æ€§èƒ½æå‡
```

---

## ğŸ” éªŒè¯æ•°æ®ä¸€è‡´æ€§

### æ£€æŸ¥DDPMæ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„è®­ç»ƒé›†

```python
# æ–¹æ³•1: æŸ¥çœ‹data_split.json
!python load_dataset.py --split_file latents_cache/data_split.json

# æ–¹æ³•2: æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ•°é‡
!ls latents_cache/user_*.pt | wc -l
# åº”è¯¥è¾“å‡º: 4650 (å¦‚æœencode_all=True)
# æˆ–: 1550 (å¦‚æœåªç¼–ç è®­ç»ƒé›†)

# æ–¹æ³•3: éªŒè¯ç‰¹å®šç”¨æˆ·çš„åˆ’åˆ†
import json
with open('latents_cache/data_split.json') as f:
    split = json.load(f)

# æŸ¥çœ‹ç”¨æˆ·1çš„åˆ’åˆ†
print(f"ç”¨æˆ·1è®­ç»ƒé›†: {len(split['users']['ID_1']['train_images'])} å¼ ")
print(f"ç”¨æˆ·1æµ‹è¯•é›†: {len(split['users']['ID_1']['test_images'])} å¼ ")
```

---

## âš™ï¸ é«˜çº§é€‰é¡¹

### åªç¼–ç è®­ç»ƒé›†ï¼ˆèŠ‚çœæ—¶é—´å’Œç©ºé—´ï¼‰

```bash
# å¦‚æœåªéœ€è¦DDPMè®­ç»ƒï¼Œä¸ç«‹å³åšåˆ†ç±»å™¨å®éªŒ
!python preprocess_latents.py --no-encode_all

# è¾“å‡º:
# Dataset split:
#   Train: 1550 images
#   Test: 3100 images
#   Total to encode: 1550 images (åªç¼–ç è®­ç»ƒé›†)
```

### åç»­è¡¥å……ç¼–ç æµ‹è¯•é›†

```python
# ä¹‹åéœ€è¦åˆ†ç±»å™¨å®éªŒæ—¶ï¼Œå¯ä»¥åªç¼–ç æµ‹è¯•é›†
# éœ€è¦æ‰‹åŠ¨å®ç°æˆ–é‡æ–°è¿è¡Œpreprocess_latents.py --encode_all
```

---

## ğŸ“ˆ å®éªŒç»“æœç¤ºä¾‹

### é¢„æœŸç»“æœæ ¼å¼

```
å®éªŒæŠ¥å‘Š
============================================================
åŸºå‡†åˆ†ç±»å™¨ï¼ˆä»…çœŸå®1550å¼ ï¼‰:
  å‡†ç¡®ç‡: 75.32%

å¢å¼ºåˆ†ç±»å™¨ç»“æœ:
  Checkpoint 50:  77.45% (+2.13%)
  Checkpoint 75:  79.21% (+3.89%) â† æœ€ä½³
  Checkpoint 100: 78.56% (+3.24%)
  Checkpoint 125: 77.89% (+2.57%)
  Checkpoint 150: 77.12% (+1.80%) â† å¯èƒ½è¿‡æ‹Ÿåˆ

ç»“è®º:
  âœ“ åˆæˆæ•°æ®æœ‰æ•ˆæå‡åˆ†ç±»å™¨æ€§èƒ½
  âœ“ æœ€ä½³æ£€æŸ¥ç‚¹: 75 (milestone)
  âœ“ æœ€å¤§æå‡: +3.89%
  âš  åæœŸæ£€æŸ¥ç‚¹æ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜DDPMå¯èƒ½è¿‡æ‹Ÿåˆ
```

---

## ğŸ“ å®Œæ•´æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒè„šæœ¬

| æ–‡ä»¶ | åŠŸèƒ½ | ä½•æ—¶ä½¿ç”¨ |
|------|------|---------|
| **preprocess_latents.py** | é¢„ç¼–ç +æ•°æ®åˆ’åˆ† | è®­ç»ƒå‰ï¼ˆä¸€æ¬¡æ€§ï¼‰ |
| **train_latent_cfg.py** | è®­ç»ƒDDPM | é¢„ç¼–ç å |
| **generate.py** | ç”Ÿæˆåˆæˆæ•°æ® | DDPMè®­ç»ƒå |
| **load_dataset.py** | åŠ è½½åˆ’åˆ†åçš„æ•°æ®é›† | åˆ†ç±»å™¨å®éªŒ |
| **classifier_experiment_example.py** | åˆ†ç±»å™¨å®éªŒç¤ºä¾‹ | è¯„ä¼°é˜¶æ®µ |

### è¾…åŠ©å·¥å…·

| æ–‡ä»¶ | åŠŸèƒ½ |
|------|------|
| **test_vae_range.py** | æµ‹è¯•VAEè¾“å‡ºèŒƒå›´ |
| **monitor_training.py** | ç›‘æ§DDPMè®­ç»ƒ |

### æ–‡æ¡£

| æ–‡ä»¶ | å†…å®¹ |
|------|------|
| **START_HERE.md** | å¿«é€Ÿå¼€å§‹æŒ‡å— |
| **CLASSIFIER_EXPERIMENT.md** | åˆ†ç±»å™¨å®éªŒè¯¦ç»†è¯´æ˜ |
| **ENCODING_COMPARISON.md** | ç¼–ç æ–¹å¼å¯¹æ¯” |

---

## ğŸ¯ å…³é”®è¦ç‚¹

### âœ… æ•°æ®é›†åˆ’åˆ†ä¿è¯

1. **å›ºå®šéšæœºç§å­ï¼ˆ42ï¼‰** - å®Œå…¨å¯å¤ç°
2. **data_split.jsonè®°å½•** - æ˜ç¡®æ¯å¼ å›¾çš„ç”¨é€”
3. **DDPMå’Œåˆ†ç±»å™¨ä½¿ç”¨ç›¸åŒåˆ’åˆ†** - ç¡®ä¿ä¸€è‡´æ€§
4. **æµ‹è¯•é›†ä¸¥æ ¼éš”ç¦»** - å¯¹DDPMä¸å¯è§

### âœ… å®éªŒæµç¨‹ä¿è¯

```
é¢„ç¼–ç é˜¶æ®µ:
  â”œâ”€ åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†ï¼ˆå›ºå®šç§å­ï¼‰
  â”œâ”€ ç¼–ç æ‰€æœ‰å›¾åƒåˆ°æ½œåœ¨ç©ºé—´
  â””â”€ ä¿å­˜data_split.json

DDPMè®­ç»ƒ:
  â””â”€ ä»…ä½¿ç”¨è®­ç»ƒé›†ï¼ˆ1550å¼ ï¼‰

åˆ†ç±»å™¨å®éªŒ:
  â”œâ”€ åŸºå‡†: è®­ç»ƒé›†1550 â†’ æµ‹è¯•é›†3100
  â””â”€ å¢å¼º: è®­ç»ƒé›†1550+åˆæˆN â†’ æµ‹è¯•é›†3100
```

---

**ç°åœ¨æ•°æ®é›†åˆ’åˆ†ä¿¡æ¯ä¼šè¢«æ­£ç¡®ä¿å­˜ï¼Œæ–¹ä¾¿åç»­æ‰€æœ‰å®éªŒï¼** âœ…ğŸ‰

